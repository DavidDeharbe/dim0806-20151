%% TODO
%% 1. illustrating figures
%% 2. add section on MST in DAGs
%%
\documentclass{beamer}
\setbeamertemplate{footline}[frame number]

\input{preamble}

\title{Aula 26: Grafos: caminho de custo mínimo}
\subtitle{Árvores de extensão mínima}
\author{David Déharbe \\
  Programa de Pós-graduação em Sistemas e Computação \\
  Universidade Federal do Rio Grande do Norte \\
  Centro de Ciências Exatas e da Terra \\
  Departamento de Informática e Matemática Aplicada}
\date{22 de maio de 2015}

\begin{document}
\selectlanguage{brazil}

\begin{frame}
  \titlepage
\end{frame}

\begin{frame}
  \frametitle{Plano}
\begin{center}
\includegraphics[height=.5\textheight]{img/map.pdf}
\end{center}
  \tableofcontents
Referência: Cormen, cap 25.
\end{frame}

\section{Introdução}

\begin{frame}
\frametitle{Introdução}

\begin{itemize}
\item qual o menor caminho para ir de Natal até o Rio de Janeiro?
\item problema de grafo?
\begin{itemize}
\item vértices: cruzamentos
\item arestas: há uma estrada/rua entre esses dois cruzamentos
\item peso: distância entre dois cruzamentos
\end{itemize}
\item muitas possibilidades!
\item soluções não tem ciclos
\item pesos podem ser outras medidas (tempo, custo financeiro, pontos turísticos)
\item \alert{otimização combinatória}: caminho de custo mínimo

\textit{single source shortest path},
\textit{all pairs shortest path}
\end{itemize}

\end{frame}

\begin{frame}
\frametitle{Definições}

\begin{center}
$G = (V, E, W)$ : grafo dirigido com pesos 
\end{center}

\begin{definition}[Custo de um caminho]
Seja um caminho $\pi = (v_0, v_1, \ldots v_k)$. Então, temos que cada $(v_i,
v_{i+1}) \in E$. O \alert{peso do caminho} $\pi$, denotado $W(\pi)$ é tal que
$$W(\pi) = \sum_{i=1}^{k} W(v_{i-1}, v_i).$$
\end{definition}

\begin{definition}[Caminho de custo mínimo]
O \alert{custo mínimo} entre dois vértices $u$ e $v$, denotado $\delta(u, v)$ é
tal que:
$$
\delta(u, v) =
\left\{
\begin{array}{ll}
\min \{ W(p) : u \overset{p}{\leadsto} v\} & \text{ se existe um caminho de $u$ até $v$}\\
\infty & \text{ caso contrário}
\end{array}
\right.
$$
\end{definition}

\end{frame}

\begin{frame}

\frametitle{Diferentes problemas de caminho de custo mínimo}

\begin{itemize}
\item se não há pesos: busca em largura
\item vértice origem fixado
\begin{itemize}
\item custo mínimo de $s$ para todos os demais vértices
\end{itemize}
\item vértice destino fixado
\begin{itemize}
\item custo mínimo de cada vértice até $s$
\item obtido do anterior com o grafo transposto
\end{itemize}
\item vértices origem e destino fixados
\begin{itemize}
\item não há solução asintoticamente melhor do que quando o vértice origem é fixado
\end{itemize}
\item entre todos os pares de vértices
\begin{itemize}
\item fixar sucessivamente a origem em todos os vértices
\item mas existe algoritmos assintoticamente melhores para este problema
\end{itemize}
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Pesos negativos}

\begin{itemize}
\item a presença ou ausência de pesos negativos muda os algoritmos possíveis
\begin{itemize}
\item sem pesos negativos: algoritmo de Dijkstra
\item com pesos negativos: algoritmo de Bellman-Ford
\end{itemize}
\item se há um ciclo tal que a soma dos pesos é negativa, então o custo
mínimo é $-\infty$!
\begin{itemize}
\item Bellman-Ford detecta ciclos negativos
\end{itemize}
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Representação de caminhos de custo mínimo}

\begin{itemize}
\item outra saída esperada: caminho de custo mínimo
\item dados: $\attrib{v}{up}$
\item o caminho de custo mínimo de $s$ até $v$ é obtido 
  seguindo $v, \attrib{v}{up}, \attrib{\attrib{v}{up}}, \ldots$
  até $s$
\item durante a aplicação do algoritmo, o valor de $\id{up}$ é 
  atualizado
\begin{itemize}
\item cada $(v, \attrib{v}{up})$ forma uma aresta da \alert{árvore dos caminhos de custo mínimo} 
\end{itemize}
\item em um grafo pode haver várias árvores dos caminhos de custo mínimo
\end{itemize}
\end{frame}

\section{Algumas propriedades de caminhos de custo mínimo}

\begin{frame}
\frametitle{Propriedades dos caminhos de custo mínimo}

\begin{enumerate}
\item Supondo que $\pi = (v_0, v_1, \ldots v_{k-1})$ é um caminho de custo
  mínimo de $v_0$ até $v_{k-1}$:
\begin{itemize}
\item O que podemos dizer do caminho $(v_i, v_{i+1}, \ldots v_{j})$ contido em
  $\pi$?
\end{itemize}
\pause
\item Supondo que: $s \overset{p}{\leadsto} v$ é o caminho de custo mínimo de $s$ até $v$
  e é composto por $s \overset{p'}{\leadsto} u$ e $(u, v)$:
\begin{itemize}
\item o que podemos dizer de $\delta(s, u)$, $\delta(s, v)$, $W(u, v)$?
\end{itemize}
\pause 
\item Em geral, se $(u, v)$ é uma aresta, qual relação podemos estabelecer
entre $\delta(s, u)$, $\delta(s, v)$ e $W(u, v)$?
\end{enumerate}
\end{frame}

\begin{frame}
\frametitle{Trecho de caminho de custo mínimo}
\framesubtitle{Propriedade}

\begin{lemma}[trecho de um caminho de custo mínimo]
Seja $\pi = (v_0, v_1, \ldots v_k)$ um caminho de custo mínimo de $v_0$ até
$v_k$, e $0 \le i \le j \le v_k$, então o trecho $(v_i, v_{i+1}, \ldots, v_j)$
de $\pi$ é um caminho de custo mínimo de $v_i$ até $v_j$.
\end{lemma}
\pause
\begin{proof}
\begin{itemize}
\item $\pi = v_0 \overset{\pi_1}{\leadsto} v_i \overset{\pi_2}{\leadsto} v_j \overset{\pi_3}{\leadsto} v_k$
\item \alert{(por contradição)} $\pi : v_0 \overset{\pi}{\leadsto} v_k$ caminho de custo mínimo de $v_0$ até $v_k$
\item $\pi_2$ é um caminho de custo não mínimo de $v_i$ até $v_j$
\item seja $\pi'$ um caminho de custo mínimo entre $v_i$ e $v_j$.
\item temos $\pi_1, \pi', \pi_3$ um caminho de $v_0$ até $v_k$ de custo menor que $\pi$
\item \alert{contradizendo} a hipótese inicial
\end{itemize}
\end{proof}
\end{frame}

\begin{frame}
\frametitle{Decomposição do custo mínimo}
\framesubtitle{Propriedade}

\begin{corollary}[decomposição de custo mínimo]
Seja $\pi$ um caminho de custo mínimo de $s$ até $v$ tal que 
$\pi$ pode ser decomposto em $s \overset{\pi'}{\leadsto} u \rightarrow v$
para algum caminho $\pi'$ e aresta $(u, v)$.

Então $\delta(s, v) = \delta(s, u) + W(u, v)$.
\end{corollary}
\pause
\begin{proof}
\begin{itemize}
\item aplicação do lema do trecho de caminho de custo mínimo
\item $\pi$ tem custo mínimo
\item $\pi'$ é um trecho de $\pi$
\item logo, $\pi'$ tem custo mínimo
\item $\delta(s, v) = W(\pi) = W(\pi')+W(u,v) = \delta(s, u) + W(u, v)$
\end{itemize}
\end{proof}
\end{frame}

\begin{frame}
\frametitle{Relação entre custos mínimos e pesos}
\framesubtitle{Propriedade}

\begin{lemma}[relação entre custos mínimos e pesos]
Para qualquer aresta $(u, v)$, temos
$$\delta(s, v) \le \delta(s, u) + W(u, v).$$
\end{lemma}
\pause
\begin{proof}
?
\end{proof}
\end{frame}

\section{Relaxação}

\begin{frame}
\frametitle{Relaxação}

\begin{itemize}
\item relaxação: reduz o limite superior (\alert{estimativa conservadora})
  do custo de um caminho
\item relaxação é aplicada repetidas vezes até chegar à solução
\item o que é \alert{relaxação}?
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Algoritmo de relaxação}

\begin{itemize}
\item $s$: um nó origem dado
\item $\attrib{v}{d}$: limite superior do custo de $s$ até $v$
\item $W(u, v)$: peso da aresta $(u, v)$
\end{itemize}
\begin{codebox}
\Procname{\proc{Relax}(u, v, W)}
\li \If $\attrib{v}{d} > \attrib{u}{d} + W(u, v)$
\li \Then $\attrib{v}{d} \gets \attrib{u}{d} + W(u, v)$
\li   $\attrib{v}{up} \gets u$
    \End
\end{codebox}
\pause
Justificativa:
\begin{itemize}
\item se a estimativa do custo de $s$ até $v$ é maior que a estimativa
  do custo de $s$ até $u$ somado ao peso de $(u, v)$;
\item existe um caminho de $s$ até $v$ com custo menor que os caminhos
  já calculados;
\item este caminho termina pela aresta $(u, v)$.
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Relaxação: ponto de partida}

\begin{itemize}
\item procedimento para iniciar com um estado compatível com a relaxação
\item $\id{d}$ é inicializado com uma estimativa conservadora: $\infty$
\item $s$: vértice origem, logo $\attrib{s}{d} = 0 = \delta(s, s)$
\end{itemize}

\begin{codebox}
\Procname{$\proc{Init-Relax}(G, s)$}
\li \For $v \in \attrib{G}{V}$
\li \Do $\attrib{v}{d} \gets \infty$
\li   $\attrib{v}{up} \gets \const{Nil}$
    \End
\li $\attrib{s}{d} \gets 0$
\end{codebox}

\end{frame}

\begin{frame}
\frametitle{Propriedades}
\framesubtitle{Algoritmo de relaxação}

\begin{codebox}
\Procname{\proc{Relax}(u, v, W)}
\li \If $\attrib{v}{d} > \attrib{u}{d} + W(u, v)$
\li \Then $\attrib{v}{d} \gets \attrib{u}{d} + W(u, v)$
\li   $\attrib{v}{up} \gets u$
    \End
\end{codebox}

\begin{lemma}[Pós-condição de $\proc{Relax}(u, v, W)$]
Após executar $\proc{Relax}(u, v, W)$, temos a seguinte relação:
$$
\attrib{v}{d} \le \attrib{u}{d} + W(u, v)
$$
\end{lemma}

\end{frame}

\begin{frame}
\frametitle{Invariante}
\framesubtitle{Algoritmo de relaxação}

\begin{lemma}[Invariante]
O invariante $\delta(s, v) \le \attrib{v}{d}$ é 
\begin{enumerate}
\item satisfeito após executar $\proc{Init-Relax}(G, s)$.
\item preservado pela execução de $\proc{Relax}(u, v, W)$
\end{enumerate}
\end{lemma}
\pause
\begin{proof}
\only<2>{
inicialização:
\begin{itemize}
\item $\delta(s, s) = 0$ ou $\delta(s, s) = -\infty$ (se $s$ estiver em um ciclo de peso negativo)
\item em todo caso $\attrib{s}{d} \ge \delta(s, s)$.
\item para $v \neq s$, $\attrib{s}{d} = \infty \ge \delta(s, v)$.
\end{itemize}
}
\only<3>{
preservação por $\proc{Relax}(u, v, W)$ (\alert{por contradição})
\begin{itemize}
\item seja $v$ o primeiro vértice tal que $\attrib{v}{d} < \delta(s, v)$
\item então, após $\proc{Relax}(u, v, W)$ temos 
$$
\begin{array}{rcl}
\attrib{u}{d} + W(u, v) & = & \attrib{v}{d} \\
  & < & \delta(s, v) \le \delta(s, u) + W(u, v)
\end{array}
$$
\item logo $\attrib{u}{d} < \delta(s, v)$
\item contradiz que $v$ foi o $1^{o}$ vértice t.q. $\attrib{v}{d} < \delta(s, v)$.
\end{itemize}
}
\end{proof}

\end{frame}

\begin{frame}
\frametitle{Vértices não alcançáveis}
\framesubtitle{Propriedades}

\begin{corollary}[Vértices não alcançáveis]
Depois de executar $\proc{Init-Relax}(G,s)$, para qualquer vértice $v$ não alcançável, temos que $\attrib{v}{d} = \delta(s, v)$.

A execução de $\proc{Relax}(u, v, W)$ mantem $\attrib{v}{d} = \delta(s, v)$.
\end{corollary}

\begin{proof}
Pelo lema do invariante, temos que $\attrib{v}{d} \ge \delta(s, v)$ sempre.
Como $\delta(s, v) = \infty$, então teremos $\attrib{v}{d}$ conserva seu
valor inicial $\infty$ sempre.
\end{proof}
\end{frame}

\begin{frame}
\frametitle{Extensão de caminho de custo mínimo}

\begin{lemma}[Extensão de caminho de custo mínimo]
Seja $s \leadsto u \rightarrow v$ um caminho de custo mínimo de $s$ até os
vértices $u$ e $v$. Se $\attrib{u}{d} = \delta(s, u)$ antes de executar
$\proc{Relax}(u, v, W)$, então $\attrib{v}{d} = \delta(s, v)$.
\end{lemma}

\begin{proof}
\begin{itemize}
\item lema do invariante: 
\begin{enumerate}
\item $\delta(s, v) \le \attrib{v}{d}$ sempre
\item se $\delta(s, u) = \attrib{u}{d}$ antes de executar $\proc{Relax}(u, v, W)$, também
$\delta(s, u) = \attrib{u}{d}$ depois
\end{enumerate}
\item Depois executar $\proc{Relax}(u, v, W)$,
$$
\begin{array}{rcll}
\attrib{v}{d} & \le & \attrib{u}{d} + W(u, v)  & \text{\footnotesize lema da pós-condição} \\
& = & \delta(s, u) + W(u, v) & \text{\footnotesize hipótese vigente} \\
& = & \delta(s, v) & \text{\footnotesize corolário decomposição de custo mínimo}
\end{array}
$$
\end{itemize}
\end{proof}
\end{frame}

\section{O algoritmo de Dijkstra}

\begin{frame}
\frametitle{Algoritmo de Dijkstra}
\framesubtitle{Princípios}

\begin{itemize}
\item Mantem um conjunto de vértices $S = \{ v \cdot \attrib{v}{d} = \delta(s, v)\}$.
\item Escolhe um vértice $u$ a inserir em $S$
\begin{itemize}
\item custo mínimo de $S$ para $u$
\end{itemize}
\item Relaxa com as arestas adjacentes a $u$
\item abordagem \alert{gulosa}
\end{itemize}

\end{frame}

\begin{frame}
\frametitle{Algoritmo de Dijkstra}

\begin{codebox}
\Procname{$\proc{Single-Source-Shortest-Path}(G, s)$}
\li $\proc{Init-Relax}(G, s)$
\li $S \gets \emptyset$
\li $Q \gets \attrib{G}{V}$
\li \While $Q \neq \emptyset$
\li \Do $u \gets \proc{Extract-Min}(Q)$
\li   $S \gets S \cup \{ u \}$
\li   \For $(u, v) \in \attrib{G}{E}$
\li   \Do $\proc{Relax}(u, v, \attrib{G}{W})$
      \End
    \End
\end{codebox}
$Q$: fila de prioridade com chave $\id{d}$

\end{frame}

\begin{frame}
\frametitle{Ilustração}
\framesubtitle{Algoritmo de Dijkstra}

Quadro

\end{frame}

\begin{frame}
\frametitle{Complexidade}
\framesubtitle{Algoritmo de Dijkstra}

Assumindo que $Q$ é um \textit{heap\/} binário...

\begin{codebox}
\Procname{$\proc{Single-Source-Shortest-Path}(G, s)$}
\li $\proc{Init-Relax}(G, s)$ \assert{\Comment $\Theta(V)$}
\li $S \gets \emptyset$
\li $Q \gets \attrib{G}{V}$ \assert{\Comment $O(V)$}
\li \While $Q \neq \emptyset$  \assert{\Comment $\Theta(V)$ repetições}
\li \Do $u \gets \proc{Extract-Min}(Q)$  \assert{\Comment $O(\lg V)$}
\li   $S \gets S \cup \{ u \}$
\li   \For $(u, v) \in \attrib{G}{E}$ \assert{\Comment total: $\Theta(E)$}
\li   \Do $\proc{Relax}(u, v, \attrib{G}{W})$ \assert{\Comment $O(\lg V)$}
      \End
    \End
\end{codebox}
\pause
\begin{center}
Total: \alert{$O(V \lg V + E \lg V)$}
\end{center}
\end{frame}

\begin{frame}
\frametitle{Correção}

Cada vez que $u$ é inserido em $S$, $\attrib{u}{d} = \delta(s, u)$
\pause
(\alert{contradição}).
\begin{itemize}
\item $v$: primeiro vértice inserido em $S$ t.q. $\attrib{v}{d} \neq \delta(v, s)$
\only<3>{\item certamente $v \neq s$, pois
\begin{itemize}
\item $s$ é o primeiro vértice inserido em $S$
\item $\attrib{s}{d}$ é 0 quando é inserido, e $\delta(s, s) = 0$.
\end{itemize}
}
\only<4->{\item $v \neq s$}
\only<6->{, $S \neq \emptyset$}
\only<8->{, $s \leadsto v$}
\only<9->{, $p = p_1 (x, y) p_2$, $s \overset{p_1}{\leadsto} x \rightarrow y \overset{p_2} \leadsto v$, $p_1 \subseteq S$, $W(p) = \delta(s, v)$}
\only<11->{, $\attrib{y}{d} = \delta(s, y)$}
\only<13->{, $\delta(s, y) \le \delta(s, v)$}
\only<5>{\item logo $S \neq \emptyset$ quand $v$ é inserido em $S$.}
\only<7>{\item necessariamente há um caminho de $s$ até $v$
\begin{enumerate}
\item senão, pelo corolário dos vértices não alcançáveis, $\attrib{v}{d} = \delta(s, v)$,
\item contradizendo hipótese vigente  $\attrib{v}{d} \neq \delta(v, s)$.
\end{enumerate}
}
\only<8>{
\item logo existe um caminho de custo mínimo entre $s$ e $v$, digamos $p$ (não necessariamente todo em $S$).
\item seja $y$ o primeiro vértice de $p$ em $V-S$ e e $x$ o predecessor de $y$ em $p$
}
\only<10>{
\item necessariamente $\attrib{x}{d} = \delta(s, x)$,
\item $x \in S$, então foi aplicado $\proc{Relax}(x, y, W)$
\item pelo lema da extensão de caminho de custo mínimo, $\attrib{y}{d} = \delta(s, y)$
}
\only<12>{
\item $y$ ocorre antes de $v$ em um caminho de custo mínimo
\item os pesos não são negativos
\item logo $\delta(s, y) \le \delta(s, v)$
\item pelo lema do invariante $\delta(s, v) \le \attrib{v}{d}$, 
\item por transitividade de $\le$, deduzimos que $\delta(s, y) \le \delta(s, v)$
}
\only<14>{
\item $v \gets \proc{Extract-Min}(Q)$
\item logo $\attrib{v}{d} \le \attrib{y}{d}$
\item temos $\attrib{v}{d} \ge \delta(s, v) \ge \delta(s, y) = \attrib{y}{d} \ge \attrib{v}{d}$
\item logo $\attrib{v}{d} = \delta(s, v)$ \alert{entramos em contradição}
}
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Teorema}

\begin{theorem}[Correção do algoritmo de Dijkstra]
O algoritmo $\proc{Single-Source-Shortest-Path}(G, s)$ calcular corretamente o 
custo dos caminhos de custo mínimo de $s$ até cada vértice de $G$.
\end{theorem}
\pause
\begin{proof}
\begin{itemize}
\item o lema do invariante garante que $\attrib{v}{d} \ge \delta(s, v)$ ao longo da execução
\item mostramos que quando um vértice é inserido em $S$, $\attrib{v}{d} = \delta(s, v)$
\item todos os vértices são inseridos em $S$.
\end{itemize}
\end{proof}
\pause
Omitimos a prova que os caminhos de custo mínimo são calculados corretamente (atributo $\id{up}$).
\end{frame}

\section{O algoritmo de Bellman-Ford}
\begin{frame}
\frametitle{Algoritmo de Bellman-Ford}
\framesubtitle{Princípios}

\begin{itemize}
\item leva em conta arestas negativas
\item detecta e reporta se existe ciclos de custo mínimo
\item também baseado na relaxação
\end{itemize}

\end{frame}

\begin{frame}
\frametitle{Algoritmo de Bellman-Ford}

\begin{codebox}
\Procname{$\proc{Single-Source-Shortest-Paths}(G, s)$}
\li $\proc{Init-Relax}(G, s)$
\li \For $i \gets 1 to |\attrib{G}{V}| - 1$
\li \Do \For $(u, v) \in \attrib{G}{E}$
\li   \Do $\proc{Relax}(u, v, \attrib{G}{W})$
      \End
    \End
\li \For $(u, v) \in \attrib{G}{E}$
\li \Do \If $\attrib{v}{d} > \attrib{u}{d} + \attrib{G}{W}(u, v)$
\li   \Then \Return $\const{False}$
      \End
    \End
\li \Return $\const{True}$
\end{codebox}

\end{frame}

\begin{frame}
\frametitle{Ilustração}
\framesubtitle{Algoritmo de Bellman-Ford}

No quadro

\end{frame}

\begin{frame}
\frametitle{Complexidade}
\framesubtitle{Algoritmo de Bellman-Ford}

\begin{codebox}
\Procname{$\proc{Single-Source-Shortest-Paths}(G, s)$}
\li $\proc{Init-Relax}(G, s)$ \assert{\Comment $\Theta(V)$} 
\li \For $i \gets 1 to |\attrib{G}{V}| - 1$ \assert{\Comment $\Theta(V)$ repetições} 
\li \Do \For $(u, v) \in \attrib{G}{E}$ \assert{\Comment $\Theta(E)$ repetições}
\li   \Do $\proc{Relax}(u, v, \attrib{G}{W})$ \assert{\Comment $\Theta(1)$}
      \End
    \End
\li \For $(u, v) \in \attrib{G}{E}$ \assert{\Comment $O(E)$ repetições}
\li \Do \If $\attrib{v}{d} > \attrib{u}{d} + \attrib{G}{W}(u, v)$
\li   \Then \Return $\const{False}$
      \End
    \End
\li \Return $\const{True}$
\end{codebox}
\pause
\alert{Total: $\Theta(V \, E)$}
\end{frame}

\begin{frame}
\frametitle{Correção}
\framesubtitle{Algoritmo de Bellman-Ford}

\begin{enumerate}
\item caso $G$ não contem ciclos de custo negativo
\item caso geral
\end{enumerate}

\end{frame}

\begin{frame}
\frametitle{Correção}
\framesubtitle{Algoritmo de Bellman-Ford}

\begin{lemma}[Bellman-Ford sem ciclos de custo negativo]
Se $G$ não possui ciclos de custo negativo, então, após executar o algoritmo de Bellman-Ford
a $G$ e $s$, temos que $\attrib{v}{d} = \delta(s, v)$ para todas as arestas alcançáveis de $s$.
\end{lemma}
\pause
\begin{proof}
\begin{itemize}
\item Seja $p = (v_0, v_1, \ldots v_k)$ um caminho de custo mínimo entre $v_0 = s$ e $v_k = v$
\only<3>{, $k \le |V|-1$}
\only<2>{\item Não há ciclos de custo negativo, logo $p$ não contem ciclo e $k \le |V|-1$.
\item Abordagem de prova:
\begin{itemize}
\item indução
\item após a iteração $i$, $\attrib{v_i}{d} = \delta(s, v_i)$
\item como há $|V|-1$ iterações, provar esta propriedade é suficiente.
\end{itemize}
}
\only<4>{
\item No \alert{caso de base}, $i = 0$,
\begin{itemize}
\item $\delta(s, v_0) = \attrib{v_0}{d} = 0$ após a inicialização;
\item mantido pelas etapas de relaxação
\end{itemize}
}
\only<5>{
\item No \alert{caso geral}, a hipótese de indução é $\attrib{v_{i-1}}{d} = \delta(s, v_{i-1})$ após
a iteração $i-1$.
\item A relaxação é aplicada a $(v_{i-1}, v_i)$ na iteração $i$, 
\item pelo lema da extensão de caminhos de custo mínimo, $\attrib{v_i}{d} = \delta(s, v_i)$ após a iteração $i$.
}
\end{itemize}
\end{proof}

\end{frame}

\begin{frame}
\frametitle{Correção}
\framesubtitle{Algoritmo de Bellman-Ford}

\begin{corollary}[Alcançabilidade e Bellman-Ford sem ciclos de custo negativo]
Se $G$ não possui ciclos de custo negativo, então, existe um caminho de $s$ até $v$ se e somente
se, após executar o algoritmo de Bellman-Ford a $G$ e $s$, temos que $\attrib{v}{d} \neq \infty$.
\end{corollary}
\end{frame}

\begin{frame}
\frametitle{Correção}
\framesubtitle{Algoritmo de Bellman-Ford}

\begin{theorem}[Correção do algoritmo de Bellman-Ford]
Se $G$ não possui ciclos de custo negativo, então o algoritmo retorna $\const{True}$ e
$\attrib{v}{d} = \delta(s, v)$ para todo $v \in V$.

Se $G$ possui um ciclo de custo negativo, então o algoritmo retorna $\const{False}$.
\end{theorem}

\end{frame}


\begin{frame}
\frametitle{Correção}
\framesubtitle{Algoritmo de Bellman-Ford}

\begin{proof}
\only<1>{
\begin{itemize}
\item Se $G$ \alert{não possui} ciclos de custo negativo
\begin{itemize}
\item Se $v$ é alcançável, temos $\attrib{v}{d} = \delta(s, v)$ (aplicação do lema)
\item Se $v$ não é alcançável, também $\attrib{v}{d} = \delta(s, v)$ (corolário dos vértices inalcançáveis)
\end{itemize}
\item Quando o laço das relaxações termina:

$\attrib{v}{d} = \delta(s, v) \le \delta(s, u) + W(u, v) = \attrib{u}{d} + W(u, v)$
\item o teste $\attrib{v}{d} > \attrib{u}{d} + W(u, v)$ nunca é verdadeiro
\item o algoritmo retorna $\const{True}$
\end{itemize}
}
\only<2>{
\begin{itemize}
\item Se $G$ \alert{possui} um ciclo de custo negativo $c = (v_0, v_1, \ldots v_k)$, com $v_0 = v_k$, alcançável a partir de $s$.
\item $\sum_{i=1}^{k} W(v_{i-1}, v_i) < 0$
\item (\alert{por contradição}) hipótese: algoritmo retorna $\const{True}$
\item logo $\attrib{v_i}{d} \le \attrib{v_{i-1}}{d} + W(v_{i-1}, v_i)$ para todo $i = 1, \ldots k$
\item $\sum_{i=1}^{k} \attrib{v_i}{d} \le \sum_{i=1}^{k} (\,\attrib{v_{i-1}}{d} + W(v_{i-1}, v_i)\,)$
\item como é um ciclo: $\sum_{i=1}^{k} \attrib{v_i}{d} = \sum_{i=1}^{k} \attrib{v_{i-1}}{d}$
\item conclusão $0 \le \sum_{i=1}^{k} W(v_{i-1}, v_i)$, \alert{contradizendo $\sum_{i=1}^{k} W(v_{i-1}, v_i) < 0$}.
\end{itemize}
}
\end{proof}
\end{frame}



\end{document}
